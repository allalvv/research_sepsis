{"paragraphs":[{"text":"import java.text.SimpleDateFormat\n\nimport org.apache.hadoop.conf.Configuration\nimport org.apache.hadoop.fs.FileSystem\nimport org.apache.spark.sql.{ SQLContext, SparkSession }\nimport org.apache.spark.{ SparkConf, SparkContext }\nimport org.apache.spark.mllib.linalg.{ DenseMatrix, Matrices, Vector, Vectors }\nimport org.apache.spark.rdd.RDD\nimport org.apache.spark.sql.SparkSession\nimport org.apache.spark.sql.DataFrame\nimport org.apache.spark.sql.types._\n\nimport scala.io.Source\nval filepath = \"file:/mnt/host/home/mimicuser/project/rawdata/\"\n\nval output_filepath =  \"file:/mnt/host/home/mimicuser/project/\"\nval folder:String = \"data/sofa_6_24/\"\n\ndef writeOutput(df:DataFrame,filepath:String,folder:String,tableName:String){\n\tdf.coalesce(1).write.format(\"com.databricks.spark.csv\").option(\"header\", \"true\").save(filepath+folder+tableName)\n}\n\ndef registerSchema(filename:String, tableName:String,tableSchema:StructType,filepath:String,sqlContext:SQLContext){\n\n    val table = sqlContext.read.\n      format(\"com.databricks.spark.csv\").\n      option(\"header\", \"true\").\n      schema(tableSchema).load(filepath+filename).cache()\n    table.registerTempTable(tableName.toUpperCase)\n}","dateUpdated":"2018-12-10T04:42:25+0000","config":{"colWidth":12,"editorMode":"ace/mode/scala","results":{},"enabled":true,"editorSetting":{"language":"scala"}},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1544416945041_-862690455","id":"20181117-145929_1555736461","dateCreated":"2018-12-10T04:42:25+0000","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"focus":true,"$$hashKey":"object:7634"},{"text":"val icustaysSchema = StructType(Array(StructField(\"ROW_ID\", IntegerType, true),\n    StructField(\"SUBJECT_ID\", IntegerType, true),\n    StructField(\"HADM_ID\", IntegerType, true),\n    StructField(\"ICUSTAY_ID\", IntegerType, true),\n    StructField(\"DBSOURCE\", StringType, true),\n    StructField(\"FIRST_CAREUNIT\", StringType, true),\n    StructField(\"LAST_CAREUNIT\", StringType, true),\n    StructField(\"FIRST_WARDID\", IntegerType, true),\n    StructField(\"LAST_WARDID\", IntegerType, true),\n    StructField(\"INTIME\", TimestampType, true),\n    StructField(\"OUTTIME\", TimestampType, true),\n    StructField(\"LOS\", DoubleType, true)))\n\nregisterSchema(\"ICUSTAYS.csv\",\"icustays\",icustaysSchema,filepath,sqlContext)\n\nval charteventsSchema = StructType(Array(StructField(\"ROW_ID\", IntegerType, true),\n    StructField(\"SUBJECT_ID\", IntegerType, true),\n    StructField(\"HADM_ID\", IntegerType, true),\n    StructField(\"ICUSTAY_ID\", IntegerType, true),\n    StructField(\"ITEMID\", IntegerType, true),\n    StructField(\"CHARTTIME\", TimestampType, true),\n    StructField(\"STORETIME\", TimestampType, true),\n    StructField(\"CGID\", IntegerType, true),\n    StructField(\"VALUE\", StringType, true),\n    StructField(\"VALUENUM\",DoubleType, true),\n    StructField(\"VALUEUOM\", StringType, true),\n    StructField(\"WARNING\", StringType, true),\n    StructField(\"ERROR\", StringType, true),\n    StructField(\"RESULTSTATUS\", StringType, true),\n    StructField(\"STOPPED\", StringType, true)))\n\nregisterSchema(\"CHARTEVENTS.csv\",\"chartevents\",charteventsSchema,filepath,sqlContext)\n\n\nval noteeventsSchema = StructType(Array(StructField(\"ROW_ID\", IntegerType, true),\n    StructField(\"SUBJECT_ID\", IntegerType, true),\n    StructField(\"HADM_ID\", IntegerType, true),\n    StructField(\"CHARTDATE\", DateType, true),\n    StructField(\"CHARTTIME\", StringType, true),\n    StructField(\"STORETIME\", TimestampType, true),\n    StructField(\"CATEGORY\", StringType, true),\n    StructField(\"DESCRIPTION\", StringType, true),\n    StructField(\"CGID\", IntegerType, true),\n    StructField(\"ISERROR\", StringType, true),\n    StructField(\"TEXT\", StringType, true)))\n\nregisterSchema(\"NOTEEVENTS_PROCESSED.csv\",\"noteevents\",noteeventsSchema,filepath,sqlContext)\n\nval inputeventsCvSchema = StructType(Array(StructField(\"ROW_ID\", IntegerType, true),\n    StructField(\"SUBJECT_ID\", IntegerType, true),\n    StructField(\"HADM_ID\", IntegerType, true),\n    StructField(\"ICUSTAY_ID\", IntegerType, true),\n    StructField(\"CHARTTIME\", TimestampType, true),\n    StructField(\"ITEMID\", IntegerType, true),\n    StructField(\"AMOUNT\", DoubleType, true),\n    StructField(\"AMOUNTUOM\", StringType, true),\n    StructField(\"RATE\", DoubleType, true),\n    StructField(\"RATEUOM\", StringType, true),\n    StructField(\"STORETIME\", TimestampType, true),\n    StructField(\"CGID\", IntegerType, true),\n    StructField(\"ORDERID\", IntegerType, true),\n    StructField(\"LINKORDERID\", IntegerType, true),\n    StructField(\"STOPPED\", StringType, true),\n    StructField(\"NEWBOTTLE\", StringType, true),\n    StructField(\"ORIGINALAMOUNT\", DoubleType, true),\n    StructField(\"ORIGINALAMOUNTUOM\", StringType, true),\n    StructField(\"ORIGINALROUTE\", StringType, true),\n    StructField(\"ORIGINALRATE\", DoubleType, true),\n    StructField(\"ORIGINALRATEUOM\", StringType, true),\n    StructField(\"ORIGINALSITE\", StringType, true)))\n\nregisterSchema(\"INPUTEVENTS_CV.csv\",\"inputevents_cv\",inputeventsCvSchema,filepath,sqlContext)\n\nval inputeventsMvSchema = StructType(Array(StructField(\"ROW_ID\", IntegerType, true),\n    StructField(\"SUBJECT_ID\", IntegerType, true),\n    StructField(\"HADM_ID\", IntegerType, true),\n    StructField(\"ICUSTAY_ID\", IntegerType, true),\n    StructField(\"STARTTIME\", TimestampType, true),\n    StructField(\"ENDTIME\", TimestampType, true),\n    StructField(\"ITEMID\", IntegerType, true),\n    StructField(\"AMOUNT\", DoubleType, true),\n    StructField(\"AMOUNTUOM\", StringType, true),\n    StructField(\"RATE\", DoubleType, true),\n    StructField(\"RATEUOM\", StringType, true),\n    StructField(\"STORETIME\", TimestampType, true),\n    StructField(\"CGID\", IntegerType, true),\n    StructField(\"ORDERID\", IntegerType, true),\n    StructField(\"LINKORDERID\", IntegerType, true),\n    StructField(\"ORDERCATEGORYNAME\", StringType, true),\n    StructField(\"SECONDARYORDERCATEGORYNAME\", StringType, true),\n    StructField(\"ORDERCOMPONENTTYPEDESCRIPTION\", StringType, true),\n    StructField(\"ORDERCATEGORYDESCRIPTION\", StringType, true),\n    StructField(\"PATIENTWEIGHT\", DoubleType, true),\n    StructField(\"TOTALAMOUNT\", DoubleType, true),\n    StructField(\"TOTALAMOUNTUOM\", StringType, true),\n    StructField(\"ISOPENBAG\", IntegerType, true),\n    StructField(\"CONTINUEINNEXTDEPT\", IntegerType, true),\n    StructField(\"CANCELREASON\", IntegerType, true),\n    StructField(\"STATUSDESCRIPTION\", StringType, true),\n    StructField(\"COMMENTS_EDITEDBY\", StringType, true),\n    StructField(\"COMMENTS_CANCELEDBY\", StringType, true),\n    StructField(\"COMMENTS_DATE\", TimestampType, true),\n    StructField(\"ORIGINALAMOUNT\", DoubleType, true),\n    StructField(\"ORIGINALRATE\", DoubleType, true)))\n\nregisterSchema(\"INPUTEVENTS_MV.csv\",\"inputevents_mv\",inputeventsMvSchema,filepath,sqlContext)\n\nval labeventsSchema = StructType(Array(StructField(\"ROW_ID\", IntegerType, true),\n    StructField(\"SUBJECT_ID\", IntegerType, true),\n    StructField(\"HADM_ID\", IntegerType, true),\n    StructField(\"ITEMID\", IntegerType, true),\n    StructField(\"CHARTTIME\", TimestampType, true),\n    StructField(\"VALUE\", StringType, true),\n    StructField(\"VALUENUM\", StringType, true),\n    StructField(\"VALUEUOM\", StringType, true),\n    StructField(\"FLAG\", StringType, true)))\n\nregisterSchema(\"LABEVENTS.csv\",\"labevents\",labeventsSchema,filepath,sqlContext)\n\nval outputeventsSchema = StructType(Array(StructField(\"ROW_ID\", IntegerType, true),\n    StructField(\"SUBJECT_ID\", IntegerType, true),\n    StructField(\"HADM_ID\", IntegerType, true),\n    StructField(\"ICUSTAY_ID\", IntegerType, true),\n    StructField(\"CHARTTIME\", TimestampType, true),\n    StructField(\"ITEMID\", IntegerType, true),\n    StructField(\"VALUE\", DoubleType, true),\n    StructField(\"VALUEUOM\", StringType, true),\n    StructField(\"STORETIME\", TimestampType, true),\n    StructField(\"CGID\", IntegerType, true),\n    StructField(\"STOPPED\", StringType, true),\n    StructField(\"NEWBOTTLE\", StringType, true),\n    StructField(\"ISERROR\", IntegerType, true)))\n\nregisterSchema(\"OUTPUTEVENTS.csv\",\"outputevents\",outputeventsSchema,filepath,sqlContext)","dateUpdated":"2018-12-10T04:42:25+0000","config":{"colWidth":12,"editorMode":"ace/mode/scala","results":{},"enabled":true,"editorSetting":{"language":"scala"}},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1544416945044_-863844702","id":"20181117-150008_257057542","dateCreated":"2018-12-10T04:42:25+0000","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:7635"},{"text":"/** load the echo data  **/\n\n/** load vitalsfirstday,labsfirstday,uofirstday,gcsfirstday\n */\n val firstday_vitals = output_filepath+folder+ \"vitals_firstday/\"\nval vitalsy_csvname = \"part*.csv\"\nval vitalsfirstday = spark.read.format(\"com.databricks.spark.csv\").\n  option(\"header\", \"true\").\n  option(\"mode\", \"DROPMALFORMED\").\n  option(\"delimiter\", \",\").\n  load(firstday_vitals+vitalsy_csvname)\nvitalsfirstday.createOrReplaceTempView(\"vitalsfirstday\")\n\n\n val firstday_bg =  output_filepath+folder+ \"bloodgas_firstday/\"\nval bg_csvname = \"part*.csv\"\nval bloodgasfirstday = spark.read.format(\"com.databricks.spark.csv\").\n  option(\"header\", \"true\").\n  option(\"mode\", \"DROPMALFORMED\").\n  option(\"delimiter\", \",\").\n  load(firstday_bg+bg_csvname)\nbloodgasfirstday.createOrReplaceTempView(\"bloodgasfirstday\")\n\n\n val firstday_bga =  output_filepath+folder+ \"bloodgas_firstdayarterial/\"\nval bga_csvname = \"part*.csv\"\nval bloodgasfirstdayarterial = spark.read.format(\"com.databricks.spark.csv\").\n  option(\"header\", \"true\").\n  option(\"mode\", \"DROPMALFORMED\").\n  option(\"delimiter\", \",\").\n  load(firstday_bga+bga_csvname)\nbloodgasfirstdayarterial.createOrReplaceTempView(\"bloodgasfirstdayarterial\")\n\n\nval firstday_vd =  output_filepath+folder+ \"ventdurations/\"\nval vd_csvname = \"part*.csv\"\nval ventdurations = spark.read.format(\"com.databricks.spark.csv\").\n  option(\"header\", \"true\").\n  option(\"mode\", \"DROPMALFORMED\").\n  option(\"delimiter\", \",\").\n  load(firstday_vd+vd_csvname)\nventdurations.createOrReplaceTempView(\"ventdurations\")\n\n\nval firstday_gcs =  output_filepath+folder+ \"gcs_firstday/\"\nval gcs_csvname = \"part*.csv\"\nval gcsfirstday = spark.read.format(\"com.databricks.spark.csv\").\n  option(\"header\", \"true\").\n  option(\"mode\", \"DROPMALFORMED\").\n  option(\"delimiter\", \",\").\n  load(firstday_gcs+gcs_csvname)\ngcsfirstday.createOrReplaceTempView(\"gcsfirstday\")\n\n\n\nval firstday_lab =  output_filepath+folder+ \"labs_firstday/\"\nval lab_csvname = \"part*.csv\"\nval labsfirstday = spark.read.format(\"com.databricks.spark.csv\").\n  option(\"header\", \"true\").\n  option(\"mode\", \"DROPMALFORMED\").\n  option(\"delimiter\", \",\").\n  load(firstday_lab+lab_csvname)\nlabsfirstday.createOrReplaceTempView(\"labsfirstday\")\n\n\n\n\nval firstday_uo =  output_filepath+folder+ \"uo_firstday/\"\nval uo_csvname = \"part*.csv\"\nval uofirstday = spark.read.format(\"com.databricks.spark.csv\").\n  option(\"header\", \"true\").\n  option(\"mode\", \"DROPMALFORMED\").\n  option(\"delimiter\", \",\").\n  load(firstday_uo+uo_csvname)\nuofirstday.createOrReplaceTempView(\"uofirstday\")\n\n\nval echo_file =   output_filepath+folder+\"echodata/\"\nval echo_csvname = \"part*.csv\"\nval echodata = spark.read.format(\"com.databricks.spark.csv\").\n  option(\"header\", \"true\").\n  option(\"mode\", \"DROPMALFORMED\").\n  option(\"delimiter\", \",\").\n  load(echo_file+echo_csvname)\nechodata.createOrReplaceTempView(\"echodata\")\n","dateUpdated":"2018-12-10T04:42:25+0000","config":{"colWidth":12,"editorMode":"ace/mode/scala","results":{},"enabled":true,"editorSetting":{"language":"scala"}},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1544416945045_-864229451","id":"20181117-150033_1205315649","dateCreated":"2018-12-10T04:42:25+0000","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:7636"},{"text":"val sofa_6_24 = sqlContext.sql(\"\"\"\nwith wt as (\n  SELECT ie.icustay_id\n    -- ensure weight is measured in kg\n    , avg(CASE\n        WHEN itemid IN (762, 763, 3723, 3580, 226512)\n          THEN valuenum\n        -- convert lbs to kgs\n        WHEN itemid IN (3581)\n          THEN valuenum * 0.45359237\n        WHEN itemid IN (3582)\n          THEN valuenum * 0.0283495231\n        ELSE null\n      END) AS weight\n  from icustays ie\n  left join chartevents c\n    on ie.icustay_id = c.icustay_id\n  WHERE valuenum IS NOT NULL\n  AND itemid IN\n  (\n    762, 763, 3723, 3580,                     -- Weight Kg\n    3581,                                     -- Weight lb\n    3582,                                     -- Weight oz\n    226512 -- Metavision: Admission Weight (Kg)\n  )\n  AND valuenum != 0\n  and charttime between  (ie.intime + interval '6' hour)  and ie.intime + interval '1' day\n  group by ie.icustay_id\n), echo2 as (\n  select ie.icustay_id, avg(weight * 0.45359237) as weight\n  from icustays ie\n  left join echodata echo\n    on ie.hadm_id = echo.hadm_id\n    and echo.chartdate >  (ie.intime + interval '6' hour) \n    and echo.chartdate < ie.intime + interval '1' day\n  group by ie.icustay_id\n), vaso_cv as (\n  select ie.icustay_id\n    -- case statement determining whether the ITEMID is an instance of vasopressor usage\n    , max(case\n            when itemid = 30047 then rate / coalesce(wt.weight,ec.weight) -- measured in mcgmin\n            when itemid = 30120 then rate -- measured in mcgkgmin ** there are clear errors, perhaps actually mcgmin\n            else null\n          end) as rate_norepinephrine\n    , max(case\n            when itemid =  30044 then rate / coalesce(wt.weight,ec.weight) -- measured in mcgmin\n            when itemid in (30119,30309) then rate -- measured in mcgkgmin\n            else null\n          end) as rate_epinephrine\n    , max(case when itemid in (30043,30307) then rate end) as rate_dopamine\n    , max(case when itemid in (30042,30306) then rate end) as rate_dobutamine\n  from icustays ie\n  inner join inputevents_cv cv\n    on ie.icustay_id = cv.icustay_id and cv.charttime between  (ie.intime + interval '6' hour) and ie.intime + interval '1' day\n  left join wt\n    on ie.icustay_id = wt.icustay_id\n  left join echo2 ec\n    on ie.icustay_id = ec.icustay_id\n  where itemid in (30047,30120,30044,30119,30309,30043,30307,30042,30306)\n  and rate is not null\n  group by ie.icustay_id\n), vaso_mv as (\n    select ie.icustay_id\n    -- case statement determining whether the ITEMID is an instance of vasopressor usage\n    , max(case when itemid = 221906 then rate end) as rate_norepinephrine\n    , max(case when itemid = 221289 then rate end) as rate_epinephrine\n    , max(case when itemid = 221662 then rate end) as rate_dopamine\n    , max(case when itemid = 221653 then rate end) as rate_dobutamine\n  from icustays ie\n  inner join inputevents_mv mv\n    on ie.icustay_id = mv.icustay_id and mv.starttime between  (ie.intime + interval '6' hour) and ie.intime + interval '1' day\n  where itemid in (221906,221289,221662,221653)\n  -- 'Rewritten' orders are not delivered to the patient\n  and statusdescription != 'Rewritten'\n  group by ie.icustay_id\n), pafi1 as\n(\n  -- join blood gas to ventilation durations to determine if patient was vent\n  select bg.icustay_id, bg.charttime\n  , PaO2FiO2\n  , case when vd.icustay_id is not null then 1 else 0 end as IsVent\n  from bloodgasfirstdayarterial bg\n  left join ventdurations vd\n    on bg.icustay_id = vd.icustay_id\n    and bg.charttime >= vd.starttime\n    and bg.charttime <= vd.endtime\n  order by bg.icustay_id, bg.charttime\n)\n, pafi2 as\n(\n  -- because pafi has an interaction between vent/PaO2:FiO2, we need two columns for the score\n  -- it can happen that the lowest unventilated PaO2/FiO2 is 68, but the lowest ventilated PaO2/FiO2 is 120\n  -- in this case, the SOFA score is 3, *not* 4.\n  select icustay_id\n  , min(case when IsVent = 0 then PaO2FiO2 else null end) as PaO2FiO2_novent_min\n  , min(case when IsVent = 1 then PaO2FiO2 else null end) as PaO2FiO2_vent_min\n  from pafi1\n  group by icustay_id\n)\n-- Aggregate the components for the score\n, scorecomp as\n(\nselect ie.icustay_id\n  , v.MeanBP_Min\n  , coalesce(cv.rate_norepinephrine, mv.rate_norepinephrine) as rate_norepinephrine\n  , coalesce(cv.rate_epinephrine, mv.rate_epinephrine) as rate_epinephrine\n  , coalesce(cv.rate_dopamine, mv.rate_dopamine) as rate_dopamine\n  , coalesce(cv.rate_dobutamine, mv.rate_dobutamine) as rate_dobutamine\n  , l.Creatinine_Max\n  , l.Bilirubin_Max\n  , l.Platelet_Min\n  , pf.PaO2FiO2_novent_min\n  , pf.PaO2FiO2_vent_min\n  , uo.UrineOutput\n  , gcs.MinGCS\nfrom icustays ie\nleft join vaso_cv cv\n  on ie.icustay_id = cv.icustay_id\nleft join vaso_mv mv\n  on ie.icustay_id = mv.icustay_id\nleft join pafi2 pf\n on ie.icustay_id = pf.icustay_id\nleft join vitalsfirstday v\n  on ie.icustay_id = v.icustay_id\nleft join labsfirstday l\n  on ie.icustay_id = l.icustay_id\nleft join uofirstday uo\n  on ie.icustay_id = uo.icustay_id\nleft join gcsfirstday gcs\n  on ie.icustay_id = gcs.icustay_id\n)\n, scorecalc as\n(\n  -- Calculate the final score\n  -- note that if the underlying data is missing, the component is null\n  -- eventually these are treated as 0 (normal), but knowing when data is missing is useful for debugging\n  select icustay_id\n  -- Respiration\n  , case\n      when PaO2FiO2_vent_min   < 100 then 4\n      when PaO2FiO2_vent_min   < 200 then 3\n      when PaO2FiO2_novent_min < 300 then 2\n      when PaO2FiO2_novent_min < 400 then 1\n      when coalesce(PaO2FiO2_vent_min, PaO2FiO2_novent_min) is null then null\n      else 0\n    end as respiration\n  -- Coagulation\n  , case\n      when platelet_min < 20  then 4\n      when platelet_min < 50  then 3\n      when platelet_min < 100 then 2\n      when platelet_min < 150 then 1\n      when platelet_min is null then null\n      else 0\n    end as coagulation\n  -- Liver\n  , case\n      -- Bilirubin checks in mg/dL\n        when Bilirubin_Max >= 12.0 then 4\n        when Bilirubin_Max >= 6.0  then 3\n        when Bilirubin_Max >= 2.0  then 2\n        when Bilirubin_Max >= 1.2  then 1\n        when Bilirubin_Max is null then null\n        else 0\n      end as liver\n  -- Cardiovascular\n  , case\n      when rate_dopamine > 15 or rate_epinephrine >  0.1 or rate_norepinephrine >  0.1 then 4\n      when rate_dopamine >  5 or rate_epinephrine <= 0.1 or rate_norepinephrine <= 0.1 then 3\n      when rate_dopamine >  0 or rate_dobutamine > 0 then 2\n      when MeanBP_Min < 70 then 1\n      when coalesce(MeanBP_Min, rate_dopamine, rate_dobutamine, rate_epinephrine, rate_norepinephrine) is null then null\n      else 0\n    end as cardiovascular\n  -- Neurological failure (GCS)\n  , case\n      when (MinGCS >= 13 and MinGCS <= 14) then 1\n      when (MinGCS >= 10 and MinGCS <= 12) then 2\n      when (MinGCS >=  6 and MinGCS <=  9) then 3\n      when  MinGCS <   6 then 4\n      when  MinGCS is null then null\n  else 0 end\n    as cns\n  -- Renal failure - high creatinine or low urine output\n  , case\n    when (Creatinine_Max >= 5.0) then 4\n    when  UrineOutput < 200 then 4\n    when (Creatinine_Max >= 3.5 and Creatinine_Max < 5.0) then 3\n    when  UrineOutput < 500 then 3\n    when (Creatinine_Max >= 2.0 and Creatinine_Max < 3.5) then 2\n    when (Creatinine_Max >= 1.2 and Creatinine_Max < 2.0) then 1\n    when coalesce(UrineOutput, Creatinine_Max) is null then null\n  else 0 end\n    as renal\n  from scorecomp\n)\nselect ie.subject_id, ie.hadm_id, ie.icustay_id\n  -- Combine all the scores to get SOFA\n  -- Impute 0 if the score is missing\n  , coalesce(respiration,0)\n  + coalesce(coagulation,0)\n  + coalesce(liver,0)\n  + coalesce(cardiovascular,0)\n  + coalesce(cns,0)\n  + coalesce(renal,0)\n  as SOFA\n, respiration\n, coagulation\n, liver\n, cardiovascular\n, cns\n, renal\nfrom icustays ie\nleft join scorecalc s\n  on ie.icustay_id = s.icustay_id\norder by ie.icustay_id\n\"\"\")\nsofa_6_24.registerTempTable(\"sofa_6_24\")\nwriteOutput(sofa_6_24,output_filepath,folder,\"sofa_6_24hr\")","dateUpdated":"2018-12-10T04:43:34+0000","config":{"colWidth":12,"editorMode":"ace/mode/scala","results":{},"enabled":true,"editorSetting":{"language":"scala"}},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1544416945046_-863075204","id":"20181117-161713_516629800","dateCreated":"2018-12-10T04:42:25+0000","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:7637"},{"dateUpdated":"2018-12-10T04:42:25+0000","config":{"colWidth":12,"editorMode":"ace/mode/scala","results":{},"enabled":true,"editorSetting":{"language":"scala"}},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1544416945046_-863075204","id":"20181117-162334_235431444","dateCreated":"2018-12-10T04:42:25+0000","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:7638"}],"name":"sofa_severityscore_6_24","id":"2DWQ7C7AY","angularObjects":{"2DY6G4N6P:shared_process":[],"2DYR2RMZA:shared_process":[],"2DYYJG7NN:shared_process":[],"2DVX43H2V:shared_process":[],"2DWED52WG:shared_process":[],"2DVN654C2:shared_process":[],"2DXH7QCKA:shared_process":[]},"config":{"looknfeel":"default","personalizedMode":"false"},"info":{}}