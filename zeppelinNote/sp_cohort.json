{"paragraphs":[{"text":"/** Notebook to create the cohort and features for sepsis1 model\n * \n * Set the path of filepath  where the mimic III data was downloaded\n * Set the path of output_filepath where you want to save all the dataframes as csv files which was created as part of final features for spesis1\n * \n * reference to sql : https://github.com/MIT-LCP/mimic-code/tree/master/concepts\n * \n * \n **/\n\n\nimport java.text.SimpleDateFormat\n\nimport org.apache.hadoop.conf.Configuration\nimport org.apache.hadoop.fs.FileSystem\nimport org.apache.spark.sql.{ SQLContext, SparkSession }\nimport org.apache.spark.{ SparkConf, SparkContext }\nimport org.apache.spark.mllib.linalg.{ DenseMatrix, Matrices, Vector, Vectors }\nimport org.apache.spark.rdd.RDD\nimport org.apache.spark.sql.SparkSession\nimport org.apache.spark.sql.DataFrame\nimport org.apache.spark.sql.types._\n\nimport scala.io.Source\n\nval filepath = \"file:/mnt/host/home/mimicuser/project/rawdata/\"\n\n\nval output_filepath =  \"file:/mnt/host/home/mimicuser/project/\"\nval folder:String =\"data/sp_cohort/\"\n\n/** write the data from DataFrame to csv **/\ndef writeOutput(df:DataFrame,filepath:String,folder:String,tableName:String){\n\tdf.coalesce(1).write.format(\"com.databricks.spark.csv\").option(\"header\", \"true\").save(filepath+folder+tableName)\n}\n\n/** method to read the file from the csv file  **/\ndef registerSchema(filename:String, tableName:String,tableSchema:StructType,filepath:String,sqlContext:SQLContext){\n\n    val table = sqlContext.read.\n      format(\"com.databricks.spark.csv\").\n      option(\"header\", \"true\").\n      schema(tableSchema).load(filepath+filename).cache()\n    table.registerTempTable(tableName.toUpperCase)\n}\n\n","dateUpdated":"2018-12-10T07:25:23+0000","config":{"colWidth":12,"editorMode":"ace/mode/scala","results":{},"enabled":true,"editorSetting":{"language":"scala"}},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1544422825112_-1749538912","id":"20181107-225106_1688358790","dateCreated":"2018-12-10T06:20:25+0000","status":"FINISHED","progressUpdateIntervalMs":500,"focus":true,"$$hashKey":"object:456","user":"anonymous","dateFinished":"2018-12-10T06:24:41+0000","dateStarted":"2018-12-10T06:24:19+0000","results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"import java.text.SimpleDateFormat\nimport org.apache.hadoop.conf.Configuration\nimport org.apache.hadoop.fs.FileSystem\nimport org.apache.spark.sql.{SQLContext, SparkSession}\nimport org.apache.spark.{SparkConf, SparkContext}\nimport org.apache.spark.mllib.linalg.{DenseMatrix, Matrices, Vector, Vectors}\nimport org.apache.spark.rdd.RDD\nimport org.apache.spark.sql.SparkSession\nimport org.apache.spark.sql.DataFrame\nimport org.apache.spark.sql.types._\nimport scala.io.Source\nfilepath: String = file:/mnt/host/Users/alla_lvov/git_study/BigDataForHealth/project/rawdata/\noutput_filepath: String = file:/mnt/host/Users/alla_lvov/git_study/BigDataForHealth/project/\nfolder: String = data/sp_cohort/\nwriteOutput: (df: org.apache.spark.sql.DataFrame, filepath: String, folder: String, tableName: String)Unit\nwarning: there was one deprecation warning; re-run with -deprecation for details\nregisterSchema: (filename: String, tableName: String, tableSchema: org.apache.spark.sql.types.StructType, filepath: String, sqlContext: org.apache.spark.sql.SQLContext)Unit\n"}]}},{"text":"\n/**load the mimic iii data required for creating the cohort for sepsis prediction **/\nval customSchema = StructType(Array(\n        StructField(\"ROW_ID\", IntegerType, true),\n        StructField(\"SUBJECT_ID\", IntegerType, true),\n        StructField(\"HADM_ID\", IntegerType, true),\n        StructField(\"ADMITTIME\", TimestampType, true),\n        StructField(\"DISCHTIME\", TimestampType, true),\n        StructField(\"DEATHTIME\", TimestampType, true),\n        StructField(\"ADMISSION_TYPE\", StringType, true),\n        StructField(\"ADMISSION_LOCATION\", StringType, true),\n        StructField(\"DISCHARGE_LOCATION\", StringType, true),\n        StructField(\"INSURANCE\", StringType, true),\n        StructField(\"LANGUAGE\", StringType, true),\n        StructField(\"RELIGION\", StringType, true),\n        StructField(\"MARITAL_STATUS\", StringType, true),\n        StructField(\"ETHNICITY\", StringType, true),\n        StructField(\"EDREGTIME\", StringType, true),\n        StructField(\"EDOUTTIME\", StringType, true),\n        StructField(\"DIAGNOSIS\", StringType, true),\n        StructField(\"HOSPITAL_EXPIRE_FLAG\", IntegerType, true),\n        StructField(\"HAS_IOEVENTS_DATA\", IntegerType, true),\n        StructField(\"HAS_CHARTEVENTS_DATA\", IntegerType, true)))\nregisterSchema(\"ADMISSIONS.csv\",\"admissions\",customSchema,filepath,sqlContext)\n\n\nval patientsSchema = StructType(Array(StructField(\"ROW_ID\", IntegerType, true),\n    StructField(\"SUBJECT_ID\", IntegerType, true),\n    StructField(\"GENDER\", StringType, true),\n    StructField(\"DOB\", TimestampType, true),\n    StructField(\"DOD\", TimestampType, true),\n    StructField(\"DOD_HOSP\", TimestampType, true),\n    StructField(\"DOD_SSN\", TimestampType, true),\nStructField(\"EXPIRE_FLAG\", IntegerType, true)))\n\nregisterSchema(\"PATIENTS.csv\",\"patients\",patientsSchema,filepath,sqlContext)\n\nval icustaysSchema = StructType(Array(StructField(\"ROW_ID\", IntegerType, true),\n    StructField(\"SUBJECT_ID\", IntegerType, true),\n    StructField(\"HADM_ID\", IntegerType, true),\n    StructField(\"ICUSTAY_ID\", IntegerType, true),\n    StructField(\"DBSOURCE\", StringType, true),\n    StructField(\"FIRST_CAREUNIT\", StringType, true),\n    StructField(\"LAST_CAREUNIT\", StringType, true),\n    StructField(\"FIRST_WARDID\", IntegerType, true),\n    StructField(\"LAST_WARDID\", IntegerType, true),\n    StructField(\"INTIME\", TimestampType, true),\n    StructField(\"OUTTIME\", TimestampType, true),\n    StructField(\"LOS\", DoubleType, true)))\n\nregisterSchema(\"ICUSTAYS.csv\",\"icustays\",icustaysSchema,filepath,sqlContext)\n\nval labeventsSchema = StructType(Array(StructField(\"ROW_ID\", IntegerType, true),\n    StructField(\"SUBJECT_ID\", IntegerType, true),\n    StructField(\"HADM_ID\", IntegerType, true),\n    StructField(\"ITEMID\", IntegerType, true),\n    StructField(\"CHARTTIME\", TimestampType, true),\n    StructField(\"VALUE\", StringType, true),\n    StructField(\"VALUENUM\", StringType, true),\n    StructField(\"VALUEUOM\", StringType, true),\n    StructField(\"FLAG\", StringType, true)))\n\nregisterSchema(\"LABEVENTS.csv\",\"labevents\",labeventsSchema,filepath,sqlContext)\n\n\n\nval charteventsSchema = StructType(Array(StructField(\"ROW_ID\", IntegerType, true),\n    StructField(\"SUBJECT_ID\", IntegerType, true),\n    StructField(\"HADM_ID\", IntegerType, true),\n    StructField(\"ICUSTAY_ID\", IntegerType, true),\n    StructField(\"ITEMID\", IntegerType, true),\n    StructField(\"CHARTTIME\", TimestampType, true),\n    StructField(\"STORETIME\", TimestampType, true),\n    StructField(\"CGID\", IntegerType, true),\n    StructField(\"VALUE\", StringType, true),\n    StructField(\"VALUENUM\",DoubleType, true),\n    StructField(\"VALUEUOM\", StringType, true),\n    StructField(\"WARNING\", StringType, true),\n    StructField(\"ERROR\", StringType, true),\n    StructField(\"RESULTSTATUS\", StringType, true),\n    StructField(\"STOPPED\", StringType, true)))\n\nregisterSchema(\"CHARTEVENTS.csv\",\"chartevents\",charteventsSchema,filepath,sqlContext)\n\n\nval diagnoses_icdSchema =  StructType(Array(StructField(\"ROW_ID\", IntegerType, true),\n     StructField(\"SUBJECT_ID\", IntegerType, true),\n    StructField(\"HADM_ID\", IntegerType, true),\n     StructField(\"SEQ_NUM\", IntegerType, true),\n      StructField(\"ICD9_CODE\", StringType, true)))\n      \n registerSchema(\"DIAGNOSES_ICD.csv\",\" diagnoses_icd\",diagnoses_icdSchema,filepath,sqlContext)     \n","dateUpdated":"2018-12-10T06:24:19+0000","config":{"colWidth":12,"editorMode":"ace/mode/scala","results":{},"enabled":true,"editorSetting":{"language":"scala"}},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1544422825187_-1789168048","id":"20181108-031927_467228248","dateCreated":"2018-12-10T06:20:25+0000","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:457","user":"anonymous","dateFinished":"2018-12-10T06:24:47+0000","dateStarted":"2018-12-10T06:24:21+0000","results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"customSchema: org.apache.spark.sql.types.StructType = StructType(StructField(ROW_ID,IntegerType,true), StructField(SUBJECT_ID,IntegerType,true), StructField(HADM_ID,IntegerType,true), StructField(ADMITTIME,TimestampType,true), StructField(DISCHTIME,TimestampType,true), StructField(DEATHTIME,TimestampType,true), StructField(ADMISSION_TYPE,StringType,true), StructField(ADMISSION_LOCATION,StringType,true), StructField(DISCHARGE_LOCATION,StringType,true), StructField(INSURANCE,StringType,true), StructField(LANGUAGE,StringType,true), StructField(RELIGION,StringType,true), StructField(MARITAL_STATUS,StringType,true), StructField(ETHNICITY,StringType,true), StructField(EDREGTIME,StringType,true), StructField(EDOUTTIME,StringType,true), StructField(DIAGNOSIS,StringType,true), StructField(HOSPIT...patientsSchema: org.apache.spark.sql.types.StructType = StructType(StructField(ROW_ID,IntegerType,true), StructField(SUBJECT_ID,IntegerType,true), StructField(GENDER,StringType,true), StructField(DOB,TimestampType,true), StructField(DOD,TimestampType,true), StructField(DOD_HOSP,TimestampType,true), StructField(DOD_SSN,TimestampType,true), StructField(EXPIRE_FLAG,IntegerType,true))\nicustaysSchema: org.apache.spark.sql.types.StructType = StructType(StructField(ROW_ID,IntegerType,true), StructField(SUBJECT_ID,IntegerType,true), StructField(HADM_ID,IntegerType,true), StructField(ICUSTAY_ID,IntegerType,true), StructField(DBSOURCE,StringType,true), StructField(FIRST_CAREUNIT,StringType,true), StructField(LAST_CAREUNIT,StringType,true), StructField(FIRST_WARDID,IntegerType,true), StructField(LAST_WARDID,IntegerType,true), StructField(INTIME,TimestampType,true), StructField(OUTTIME,TimestampType,true), StructField(LOS,DoubleType,true))\nlabeventsSchema: org.apache.spark.sql.types.StructType = StructType(StructField(ROW_ID,IntegerType,true), StructField(SUBJECT_ID,IntegerType,true), StructField(HADM_ID,IntegerType,true), StructField(ITEMID,IntegerType,true), StructField(CHARTTIME,TimestampType,true), StructField(VALUE,StringType,true), StructField(VALUENUM,StringType,true), StructField(VALUEUOM,StringType,true), StructField(FLAG,StringType,true))\ncharteventsSchema: org.apache.spark.sql.types.StructType = StructType(StructField(ROW_ID,IntegerType,true), StructField(SUBJECT_ID,IntegerType,true), StructField(HADM_ID,IntegerType,true), StructField(ICUSTAY_ID,IntegerType,true), StructField(ITEMID,IntegerType,true), StructField(CHARTTIME,TimestampType,true), StructField(STORETIME,TimestampType,true), StructField(CGID,IntegerType,true), StructField(VALUE,StringType,true), StructField(VALUENUM,DoubleType,true), StructField(VALUEUOM,StringType,true), StructField(WARNING,StringType,true), StructField(ERROR,StringType,true), StructField(RESULTSTATUS,StringType,true), StructField(STOPPED,StringType,true))\ndiagnoses_icdSchema: org.apache.spark.sql.types.StructType = StructType(StructField(ROW_ID,IntegerType,true), StructField(SUBJECT_ID,IntegerType,true), StructField(HADM_ID,IntegerType,true), StructField(SEQ_NUM,IntegerType,true), StructField(ICD9_CODE,StringType,true))\n"}]}},{"text":"val inputeventsMvSchema = StructType(Array(StructField(\"ROW_ID\", IntegerType, true),\n    StructField(\"SUBJECT_ID\", IntegerType, true),\n    StructField(\"HADM_ID\", IntegerType, true),\n    StructField(\"ICUSTAY_ID\", IntegerType, true),\n    StructField(\"STARTTIME\", TimestampType, true),\n    StructField(\"ENDTIME\", TimestampType, true),\n    StructField(\"ITEMID\", IntegerType, true),\n    StructField(\"AMOUNT\", DoubleType, true),\n    StructField(\"AMOUNTUOM\", StringType, true),\n    StructField(\"RATE\", DoubleType, true),\n    StructField(\"RATEUOM\", StringType, true),\n    StructField(\"STORETIME\", TimestampType, true),\n    StructField(\"CGID\", IntegerType, true),\n    StructField(\"ORDERID\", IntegerType, true),\n    StructField(\"LINKORDERID\", IntegerType, true),\n    StructField(\"ORDERCATEGORYNAME\", StringType, true),\n    StructField(\"SECONDARYORDERCATEGORYNAME\", StringType, true),\n    StructField(\"ORDERCOMPONENTTYPEDESCRIPTION\", StringType, true),\n    StructField(\"ORDERCATEGORYDESCRIPTION\", StringType, true),\n    StructField(\"PATIENTWEIGHT\", DoubleType, true),\n    StructField(\"TOTALAMOUNT\", DoubleType, true),\n    StructField(\"TOTALAMOUNTUOM\", StringType, true),\n    StructField(\"ISOPENBAG\", IntegerType, true),\n    StructField(\"CONTINUEINNEXTDEPT\", IntegerType, true),\n    StructField(\"CANCELREASON\", IntegerType, true),\n    StructField(\"STATUSDESCRIPTION\", StringType, true),\n    StructField(\"COMMENTS_EDITEDBY\", StringType, true),\n    StructField(\"COMMENTS_CANCELEDBY\", StringType, true),\n    StructField(\"COMMENTS_DATE\", TimestampType, true),\n    StructField(\"ORIGINALAMOUNT\", DoubleType, true),\n    StructField(\"ORIGINALRATE\", DoubleType, true)))\n\nregisterSchema(\"INPUTEVENTS_MV.csv\",\"inputevents_mv\",inputeventsMvSchema,filepath,sqlContext)","dateUpdated":"2018-12-10T06:24:20+0000","config":{"colWidth":12,"editorMode":"ace/mode/scala","results":{},"enabled":true,"editorSetting":{"language":"scala"}},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1544422825200_-1783396815","id":"20181115-180448_1594377783","dateCreated":"2018-12-10T06:20:25+0000","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:458","user":"anonymous","dateFinished":"2018-12-10T06:24:48+0000","dateStarted":"2018-12-10T06:24:42+0000","results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"inputeventsMvSchema: org.apache.spark.sql.types.StructType = StructType(StructField(ROW_ID,IntegerType,true), StructField(SUBJECT_ID,IntegerType,true), StructField(HADM_ID,IntegerType,true), StructField(ICUSTAY_ID,IntegerType,true), StructField(STARTTIME,TimestampType,true), StructField(ENDTIME,TimestampType,true), StructField(ITEMID,IntegerType,true), StructField(AMOUNT,DoubleType,true), StructField(AMOUNTUOM,StringType,true), StructField(RATE,DoubleType,true), StructField(RATEUOM,StringType,true), StructField(STORETIME,TimestampType,true), StructField(CGID,IntegerType,true), StructField(ORDERID,IntegerType,true), StructField(LINKORDERID,IntegerType,true), StructField(ORDERCATEGORYNAME,StringType,true), StructField(SECONDARYORDERCATEGORYNAME,StringType,true), StructField(ORDERCOMPONENT..."}]}},{"text":"/*  vitals observvation information  */\nval vitals_obs =  sqlContext.sql(\"\"\"\n  with vitals_pvt(\n     select ie.subject_id, ie.hadm_id, ie.icustay_id\n     \n  , case\n   \n    when itemid in (211,220045) and valuenum > 0 and valuenum < 300 then 1 -- HeartRate\n    when itemid in (51,442,455,6701,220179,220050) and valuenum > 0 and valuenum < 400 then 2 -- SysBP\n    when itemid in (8368,8440,8441,8555,220180,220051) and valuenum > 0 and valuenum < 300 then 3 -- DiasBP\n    when itemid in (456,52,6702,443,220052,220181,225312) and valuenum > 0 and valuenum < 300 then 4 -- MeanBP\n    when itemid in (615,618,220210,224690) and valuenum > 0 and valuenum < 70 then 5 -- RespRate\n    when itemid in (223761,678) and valuenum > 70 and valuenum < 120  then 6 -- TempF, converted to degC in valuenum call\n    when itemid in (223762,676) and valuenum > 10 and valuenum < 50  then 6 -- TempC\n    when itemid in (646,220277) and valuenum > 0 and valuenum <= 100 then 7 -- SpO2\n   \n\n    else null end as VitalID\n    -- convert F to C\n  , case when itemid in (223761,678) then (valuenum-32)/1.8 else valuenum end as valuenum\n\n  from icustays ie\n  left join chartevents ce\n  on ie.subject_id = ce.subject_id and ie.hadm_id = ce.hadm_id and ie.icustay_id = ce.icustay_id\n  and ce.charttime between ie.intime and FROM_UNIXTIME(UNIX_TIMESTAMP(ie.intime) + 86400)\n \n  -- exclude rows marked as error\n  -- and ce.error IS DISTINCT FROM 1\n  WHERE (ce.error = 0 OR ce.error IS NULL) and \n  ce.itemid in\n  (\n  -- HEART RATE\n  211, --\"Heart Rate\"\n  220045, --\"Heart Rate\"\n\n  -- Systolic/diastolic\n\n  51, --\tArterial BP [Systolic]\n  442, --\tManual BP [Systolic]\n  455, --\tNBP [Systolic]\n  6701, --\tArterial BP #2 [Systolic]\n  220179, --\tNon Invasive Blood Pressure systolic\n  220050, --\tArterial Blood Pressure systolic\n  \n  8368, --\tArterial BP [Diastolic]\n  8440, --\tManual BP [Diastolic]\n  8441, --\tNBP [Diastolic]\n  8555, --\tArterial BP #2 [Diastolic]\n  220180, --\tNon Invasive Blood Pressure diastolic\n  220051, --\tArterial Blood Pressure diastolic\n\n   -- MEAN ARTERIAL PRESSURE\n  456, --\"NBP Mean\"\n  52, --\"Arterial BP Mean\"\n  6702, --\tArterial BP Mean #2\n  443, --\tManual BP Mean(calc)\n  220052, --\"Arterial Blood Pressure mean\"\n  220181, --\"Non Invasive Blood Pressure mean\"\n  225312, --\"ART BP mean\"\n\n  -- RESPIRATORY RATE\n  618,--\tRespiratory Rate\n  615,--\tResp Rate (Total)\n  220210,--\tRespiratory Rate\n  224690, --\tRespiratory Rate (Total)\n\n\n  -- SPO2, peripheral\n  646, 220277,\n\n\n  -- TEMPERATURE\n  223762, -- \"Temperature Celsius\"\n  676,\t-- \"Temperature C\"\n  223761, -- \"Temperature Fahrenheit\"\n  678 --\t\"Temperature F\"\n\n  )\n )\n SELECT pvt.subject_id, pvt.hadm_id, pvt.icustay_id\n -- Easier names\n, count(case when VitalID = 1 then valuenum end) as HeartRate\n\n,  count(case when VitalID = 2 then valuenum  end) as SysBP\n\n,  count(case when VitalID = 3 then valuenum end) as DiasBP\n\n, count(case when VitalID = 4 then valuenum end) as MeanBP\n\n,  count(case when VitalID = 5 then valuenum  end) as RespRate\n\n,  count(case when VitalID = 6 then valuenum end) as TempC\n, count(case when VitalID = 7 then valuenum  end) as SpO2\n\n\n\nFROM vitals_pvt as pvt\ngroup by pvt.subject_id, pvt.hadm_id, pvt.icustay_id\norder by pvt.subject_id, pvt.hadm_id, pvt.icustay_id\n \n\"\"\")\nvitals_obs.registerTempTable(\"vitals_obs\")\n\nwriteOutput(vitals_obs,output_filepath,folder,\"vitals_observation\")\n","dateUpdated":"2018-12-10T06:24:20+0000","config":{"colWidth":12,"editorMode":"ace/mode/scala","results":{},"enabled":true,"editorSetting":{"language":"scala"}},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1544422825217_-1703753792","id":"20181112-165650_1805755126","dateCreated":"2018-12-10T06:20:25+0000","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:459","user":"anonymous","dateFinished":"2018-12-10T06:55:16+0000","dateStarted":"2018-12-10T06:24:48+0000","results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"vitals_obs: org.apache.spark.sql.DataFrame = [subject_id: int, hadm_id: int ... 8 more fields]\nwarning: there was one deprecation warning; re-run with -deprecation for details\n"}]}},{"text":"/** wbc count observations **/\nval wbc_obs =  sqlContext.sql(\"\"\"\n\n with lab_pvt as (\n  select ie.subject_id, ie.hadm_id, ie.icustay_id\n  -- here we assign labels to ITEMIDs\n  -- this also fuses together multiple ITEMIDs containing the same data\n  , case\n    when itemid = 51300 then 'WBC'\n        when itemid = 51301 then 'WBC'\n      else null\n    end as label\n  , -- add in some sanity checks on the values\n  -- the where clause below requires all valuenum to be > 0, so these are only upper limit checks\n    case\n      when itemid = 51300 and valuenum >  1000 then null -- 'WBC'\n      when itemid = 51301 and valuenum >  1000 then null -- 'WBC'\n    else le.valuenum\n    end as valuenum\n\n   from icustays ie\n  left join labevents le\n    on le.subject_id = ie.subject_id and le.hadm_id = ie.hadm_id\n     and le.charttime between (ie.intime - interval '6' hour) and (ie.intime + interval '1' day)\n    and le.ITEMID in\n    (\n     -- comment is: LABEL | CATEGORY | FLUID | NUMBER OF ROWS IN LABEVENTS\n     51301 -- WHITE BLOOD CELLS | HEMATOLOGY | BLOOD | 753301\n    )\n    and valuenum is not null and valuenum > 0 -- lab values cannot be 0 and cannot be negative\n  )\n select\n  pvt.subject_id, pvt.hadm_id, pvt.icustay_id,\n   count (case when label = 'WBC' then valuenum else null end) as WBC_observation_count\n   \n  from lab_pvt as pvt\ngroup by pvt.subject_id, pvt.hadm_id, pvt.icustay_id\norder by pvt.subject_id, pvt.hadm_id, pvt.icustay_id\n\"\"\")\nwbc_obs.registerTempTable(\"wbc_obs\")\nwriteOutput(wbc_obs,output_filepath,folder,\"wbc_observation\")\n\n \n ","dateUpdated":"2018-12-10T06:24:21+0000","config":{"colWidth":12,"editorMode":"ace/mode/scala","results":{},"enabled":true,"editorSetting":{"language":"scala"}},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1544422825221_-1705292788","id":"20181112-173243_564744718","dateCreated":"2018-12-10T06:20:25+0000","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:460","user":"anonymous","dateFinished":"2018-12-10T06:57:04+0000","dateStarted":"2018-12-10T06:24:48+0000","results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"wbc_obs: org.apache.spark.sql.DataFrame = [subject_id: int, hadm_id: int ... 2 more fields]\nwarning: there was one deprecation warning; re-run with -deprecation for details\n"}]}},{"text":"/** This query provides a useful set of information regarding patient\n--  ICU stays. The information is combined from the admissions, patients, and\n--  icustays tables. It includes age, length of stay, sequence, and expiry flags.\n--  and patients who are 18yrs or older\n**/\nval icustay_details =  sqlContext.sql(\"\"\"\n\n\nSELECT ie.subject_id, ie.hadm_id, ie.icustay_id\n\n-- patient level factors\n, pat.gender\n\n-- hospital level factors\n, FROM_UNIXTIME(UNIX_TIMESTAMP(adm.admittime)) as admittime , FROM_UNIXTIME(UNIX_TIMESTAMP(adm.dischtime)) as dischtime\n,round(( (UNIX_TIMESTAMP(adm.dischtime)-UNIX_TIMESTAMP(adm.admittime))/60.0/60.0/24.0),2) AS los_hospital\n\n,YEAR(adm.admittime) - YEAR(pat.dob) AS  admission_age\n\n, adm.ethnicity, adm.admission_type\n, adm.hospital_expire_flag\n, DENSE_RANK() OVER (PARTITION BY adm.subject_id ORDER BY adm.admittime) AS hospstay_seq\n, CASE\n    WHEN DENSE_RANK() OVER (PARTITION BY adm.subject_id ORDER BY adm.admittime) = 1 THEN True\n    ELSE False END AS first_hosp_stay\n\n-- icu level factors\n, FROM_UNIXTIME(UNIX_TIMESTAMP(ie.intime)) as intime, FROM_UNIXTIME(UNIX_TIMESTAMP(ie.outtime))as outtime\n, (UNIX_TIMESTAMP(ie.outtime)-UNIX_TIMESTAMP( ie.intime))/60.0/60.0/24.0 AS  los_icu\n\n, DENSE_RANK() OVER (PARTITION BY ie.hadm_id ORDER BY ie.intime) AS icustay_seq\n\n-- first ICU stay *for the current hospitalization*\n, CASE\n    WHEN DENSE_RANK() OVER (PARTITION BY ie.hadm_id ORDER BY ie.intime) = 1 THEN True\n    ELSE False END AS first_icu_stay\n\n, case when first_careunit in ('CSRU') OR last_careunit in ('CSRU') THEN 1\n    Else 0 END as  CSRU_Service\n, case when first_careunit in ('MICU') OR last_careunit in ('MICU') THEN 1\n    Else 0 END as  MICU_Service\n, case when first_careunit in ('SICU') OR last_careunit in ('SICU') THEN 1\n    Else 0 END as  SICU_Service \n, case when last_careunit in ('MICU') THEN 1\n    Else 0 END as  In_MICU\n\nFROM icustays ie\nINNER JOIN admissions adm\n    ON ie.hadm_id = adm.hadm_id\nINNER JOIN patients pat\n    ON ie.subject_id = pat.subject_id\n   where( YEAR(adm.admittime) - YEAR(pat.dob)) >18\n   \n  \n   \n    \nORDER BY ie.subject_id, adm.admittime, ie.intime\n\"\"\")\n\nicustay_details.registerTempTable(\"icustay_details\")\n\nwriteOutput(icustay_details,output_filepath,folder,\"icustay_details\")\n\n","dateUpdated":"2018-12-10T06:24:21+0000","config":{"colWidth":12,"editorMode":"ace/mode/scala","results":{},"enabled":true,"editorSetting":{"language":"scala"}},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1544422825223_-1704523290","id":"20181108-203026_1826632727","dateCreated":"2018-12-10T06:20:25+0000","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:461","user":"anonymous","dateFinished":"2018-12-10T06:57:21+0000","dateStarted":"2018-12-10T06:55:17+0000","results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"icustay_details: org.apache.spark.sql.DataFrame = [subject_id: int, hadm_id: int ... 20 more fields]\nwarning: there was one deprecation warning; re-run with -deprecation for details\n"}]}},{"text":"/** load all the output data into tables  **/\nval vitals_obs_data = output_filepath+folder+ \"vitals_observation/\"\nval vitals_csvname = \"part*.csv\"\nval vitalsobservationSchema = StructType(Array(\n    StructField(\"subject_id\", IntegerType, true),\n    StructField(\"hadm_id\", IntegerType, true),\n    StructField(\"icustay_id\", IntegerType, true),\n    StructField(\"HeartRate\", IntegerType, true),\n    StructField(\"SysBP\", IntegerType, true),\n    StructField(\"DiasBP\", IntegerType, true),\n    StructField(\"MeanBP\", IntegerType, true),\n    StructField(\"RespRate\", IntegerType, true),\n    StructField(\"TempC\", IntegerType, true),\n    StructField(\"SpO2\", IntegerType, true)))\n\nregisterSchema(vitals_csvname,\"vitalsObservation\",vitalsobservationSchema,vitals_obs_data,sqlContext)\n\nval wbc_obs_data = output_filepath+folder+ \"wbc_observation/\"\nval wbc_csvname = \"part*.csv\"\nval wbcobservationSchema = StructType(Array(\n    StructField(\"subject_id\", IntegerType, true),\n    StructField(\"hadm_id\", IntegerType, true),\n    StructField(\"icustay_id\", IntegerType, true),\n    StructField(\"WBC_observation_count\", IntegerType, true)))\n\nregisterSchema(wbc_csvname,\"wbcobservation\",wbcobservationSchema,wbc_obs_data,sqlContext)\n\n\n","dateUpdated":"2018-12-10T06:24:21+0000","config":{"colWidth":12,"editorMode":"ace/mode/scala","results":{"0":{"graph":{"mode":"table","height":221,"optionOpen":false}}},"enabled":true,"editorSetting":{"language":"scala"}},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1544422825226_-1705677537","id":"20181112-194302_1170095352","dateCreated":"2018-12-10T06:20:25+0000","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:462","user":"anonymous","dateFinished":"2018-12-10T06:57:23+0000","dateStarted":"2018-12-10T06:57:05+0000","results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"vitals_obs_data: String = file:/mnt/host/Users/alla_lvov/git_study/BigDataForHealth/project/data/sp_cohort/vitals_observation/\nvitals_csvname: String = part*.csv\nvitalsobservationSchema: org.apache.spark.sql.types.StructType = StructType(StructField(subject_id,IntegerType,true), StructField(hadm_id,IntegerType,true), StructField(icustay_id,IntegerType,true), StructField(HeartRate,IntegerType,true), StructField(SysBP,IntegerType,true), StructField(DiasBP,IntegerType,true), StructField(MeanBP,IntegerType,true), StructField(RespRate,IntegerType,true), StructField(TempC,IntegerType,true), StructField(SpO2,IntegerType,true))\nwbc_obs_data: String = file:/mnt/host/Users/alla_lvov/git_study/BigDataForHealth/project/data/sp_cohort/wbc_observation/\nwbc_csvname: String = part*.csv\nwbcobservationSchema: org.apache.spark.sql.types.StructType = StructType(StructField(subject_id,IntegerType,true), StructField(hadm_id,IntegerType,true), StructField(icustay_id,IntegerType,true), StructField(WBC_observation_count,IntegerType,true))\n"}]}},{"text":"/* get the ICD-9 for sepsis1 and septic_shock */\nval icd9_sepsis1 =\n sqlContext.sql(\"\"\"\n \n WITH co_dx AS\n(\n\tSELECT subject_id, hadm_id\n\t-- sepsis codes\n  , MAX(\n      CASE\n        WHEN icd9_code = '99591' THEN 1\n        \tWHEN icd9_code = '99592' THEN 1\n      ELSE 0 END\n    ) AS sepsis1\n\t\n  , MAX(\n      CASE\n        WHEN icd9_code = '78552' THEN 1\n      ELSE 0 END\n    ) AS septic_shock\n  FROM diagnoses_icd\n  GROUP BY hadm_id, subject_id\n)\nselect\n  adm.subject_id\n  , adm.hadm_id\n  ,adm.icustay_id\n  , co_dx.sepsis1 as sepsis1\n \n  , co_dx.septic_shock as septicshock\nFROM   icustay_details adm\ninner join co_dx\n  on adm.hadm_id = co_dx.hadm_id and adm.subject_id = co_dx.subject_id\norder by adm.subject_id, adm.hadm_id\n \"\"\")\n \n icd9_sepsis1.registerTempTable(\"icd9_sepsis1\")\n \n//icd9_sepsis1.show()\nwriteOutput(icd9_sepsis1,output_filepath,folder,\"icd9_sepsis1\") \n ","dateUpdated":"2018-12-10T06:24:21+0000","config":{"colWidth":12,"editorMode":"ace/mode/scala","results":{},"enabled":true,"editorSetting":{"language":"scala"}},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1544422825226_-1705677537","id":"20181125-214500_1360331144","dateCreated":"2018-12-10T06:20:25+0000","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:463","user":"anonymous","dateFinished":"2018-12-10T06:57:36+0000","dateStarted":"2018-12-10T06:57:22+0000","results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"icd9_sepsis1: org.apache.spark.sql.DataFrame = [subject_id: int, hadm_id: int ... 3 more fields]\nwarning: there was one deprecation warning; re-run with -deprecation for details\n"}]}},{"text":" /** combine icustay_details, vitals observations, wbc observations based on age >18, atleaast 10 vital observations \n  * and atleast 2 wbc count \n \n\n  **/\nval sp_cohort_icd =  sqlContext.sql(\"\"\"\nselect ie.*,\n vobs.HeartRate as HeartRate_obs_count ,\n vobs.SysBP as SysBP_obs_count,\n vobs.DiasBP as DiasBP_obs_count,\n vobs.MeanBP as MeanBP_obs_count,\n vobs.RespRate as RespRate_obs_count,\n vobs.TempC as TempC_obs_count,\n vobs.SpO2 as SpO2_obs_count,\n wobs.WBC_observation_count,\n  ic.sepsis1 as sepsis1_icd,\n\n ic.septicshock as sepctic_shock_icd\n    from icustay_details ie\n --    LEFT JOIN icd9_sepsis as co_dx\n --       on ie.subject_id = co_dx.subject_id and ie.hadm_id = co_dx.subject_id\n    left join  vitalsObservation vobs\n         ON ie.subject_id = vobs.subject_id and ie.hadm_id=vobs.hadm_id and  ie.icustay_id = vobs.icustay_id\n    left JOIN wbcobservation wobs\n         ON ie.subject_id = wobs.subject_id and ie.hadm_id=wobs.hadm_id and  ie.icustay_id = wobs.icustay_id\n    left join icd9_sepsis1 ic\n         on ie.subject_id=ic.subject_id and ie.hadm_id=ic.hadm_id and  ie.icustay_id= ic.icustay_id\n    where ie.admission_age > 18 and icustay_seq =1 \n --   and (vobs.HeartRate>=10 and vobs.SysBP>=10 and DiasBP>=10 and MeanBP>=10 and RespRate>=10 and TempC>=10 and SpO2>=10)\n --   and wobs.WBC_observation_count>=2\n  --  and ( co_dx.sepsis =1 or co_dx.severe_sepsis=1)\n    order by  ie.subject_id, ie.hadm_id, ie.icustay_id\n    \"\"\")\n    \n    sp_cohort_icd.registerTempTable(\"sp_cohort_icd\")\n\nwriteOutput(sp_cohort_icd,output_filepath,folder,\"sp_cohort_icd\")\n    ","dateUpdated":"2018-12-10T06:24:21+0000","config":{"colWidth":12,"editorMode":"ace/mode/scala","results":{},"enabled":true,"editorSetting":{"language":"scala"}},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1544422825229_-1708370779","id":"20181112-214808_1298216088","dateCreated":"2018-12-10T06:20:25+0000","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:464","user":"anonymous","dateFinished":"2018-12-10T06:58:10+0000","dateStarted":"2018-12-10T06:57:23+0000","results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"sp_cohort_icd: org.apache.spark.sql.DataFrame = [subject_id: int, hadm_id: int ... 30 more fields]\nwarning: there was one deprecation warning; re-run with -deprecation for details\n"}]}},{"text":"/** get the first and last charttime observing  sysBP for the cohort patient required for finding the hyporegion  **/\n\nval sbp_region =  sqlContext.sql(\"\"\"\n   with sbp_pvt(\n     select  ie.icustay_id,\n     -- valuenum,charttime,\n     case when itemid in (51,442,455,6701,220179,220050) and valuenum < 90 then charttime else null end as hyporegion -- SysBP\n    -- , case when itemid in (51,442,455,6701,220179,220050) and valuenum < 90 then 1 else 0 end as is_septiczone\n     -- ,case when itemid in (51,442,455,6701,220179,220050) and valuenum > 0 and valuenum < 400 then charttime else null end as bptime -- SysBP\n     from sp_cohort_icd ie\n   --   from icustays ie\n     inner join chartevents ce\n     on\n    --  ie.subject_id = ce.subject_id and ie.hadm_id = ce.hadm_id and\n     ie.icustay_id = ce.icustay_id\n    -- AND (ce.charttime > FROM_UNIXTIME(UNIX_TIMESTAMP(ie.intime) - 43200))\n   --  AND (ce.charttime < FROM_UNIXTIME(UNIX_TIMESTAMP(ie.outtime) + 43200))\n   --   and ce.charttime between FROM_UNIXTIME(UNIX_TIMESTAMP(ie.intime)) and FROM_UNIXTIME(UNIX_TIMESTAMP(ie.intime) + 86400)\n \n      -- exclude rows marked as error\n      -- and ce.error IS DISTINCT FROM 1\n      WHERE \n      -- (ce.error = 0 OR ce.error IS NULL) and \n      ce.itemid in\n      (\n         51, --\tArterial BP [Systolic]\n         442, --\tManual BP [Systolic]\n         455, --\tNBP [Systolic]\n         6701, --\tArterial BP #2 [Systolic]\n         220179, --\tNon Invasive Blood Pressure systolic\n         220050 --\tArterial Blood Pressure systolic\n      )\n   --   and ce.icustay_id=232134\n       and ce.charttime between ie.intime and FROM_UNIXTIME(UNIX_TIMESTAMP(ie.intime) + 86400)\n     -- and( ce.charttime between FROM_UNIXTIME(UNIX_TIMESTAMP(ie.intime)) and FROM_UNIXTIME(UNIX_TIMESTAMP(ie.intime) + 86400))\n      order by charttime\n     -- group by ce.icustay_id\n   )\n    select icustay_id,FROM_UNIXTIME(UNIX_TIMESTAMP(min(hyporegion))) as start_hyporegion,FROM_UNIXTIME(UNIX_TIMESTAMP(max(hyporegion))) as end_hyporegion\n   from sbp_pvt\n    group by icustay_id\n   \n \n\"\"\")\nsbp_region.registerTempTable(\"sbp_region\")\n\nwriteOutput(sbp_region,output_filepath,folder,\"sbp_region\")\n\n ","dateUpdated":"2018-12-10T06:24:21+0000","config":{"colWidth":12,"editorMode":"ace/mode/scala","results":{},"enabled":true,"editorSetting":{"language":"scala"}},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1544422825230_-1707216533","id":"20181114-002057_2026293125","dateCreated":"2018-12-10T06:20:25+0000","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:465","user":"anonymous","dateFinished":"2018-12-10T07:00:13+0000","dateStarted":"2018-12-10T06:57:37+0000","results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"sbp_region: org.apache.spark.sql.DataFrame = [icustay_id: int, start_hyporegion: string ... 1 more field]\nwarning: there was one deprecation warning; re-run with -deprecation for details\n"}]}},{"text":"/***\n * sql to calculate the fluid in take by the patients within the hyporegions\n * \n **/\nval sbp_septic =  sqlContext.sql(\"\"\"\n  with fluid_pvt as (\n    select ie.icustay_id,ce.amount,ce.starttime\n      \n        \n     from sbp_region ie\n     left join inputevents_mv ce\n     on  ie.icustay_id = ce.icustay_id\n    \n      WHERE \n     ordercategoryname='01-Drips' and AMOUNTUOM='ml'\n     -- and (ce.starttime between FROM_UNIXTIME( UNIX_TIMESTAMP(ie.start_hyporegion)-3600) and FROM_UNIXTIME(UNIX_TIMESTAMP(ie.end_hyporegion)/2))\n      and ie.start_hyporegion is not null\n    --  and ce.icustay_id=232134\n      and ce.starttime between ie.start_hyporegion and FROM_UNIXTIME(UNIX_TIMESTAMP(ie.start_hyporegion) + 86400)\n     -- and (ce.starttime >  FROM_UNIXTIME( UNIX_TIMESTAMP(ie.start_hyporegion)-3600))\n    --  and  (ce.starttime <  FROM_UNIXTIME(UNIX_TIMESTAMP(ie.end_hyporegion)/2))\n      \n      order by ce.starttime\n    )\n    \n    select icustay_id,sum(amount) as fluid_intake_amt,\n    case when sum(amount) > 600 then 1 else 0 end as is_septic\n    \n    from  fluid_pvt \n    \n    \n    group by icustay_id\n    \n      \n\"\"\")\nsbp_septic.registerTempTable(\"sbp_septic\")\n\nwriteOutput(sbp_septic,output_filepath,folder,\"sbp_septic\")\n","dateUpdated":"2018-12-10T06:24:21+0000","config":{"colWidth":12,"editorMode":"ace/mode/scala","results":{},"enabled":true,"editorSetting":{"language":"scala"}},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1544422825232_-1697213061","id":"20181114-233414_1669786151","dateCreated":"2018-12-10T06:20:25+0000","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:466","user":"anonymous","dateFinished":"2018-12-10T07:02:44+0000","dateStarted":"2018-12-10T06:58:11+0000","results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"sbp_septic: org.apache.spark.sql.DataFrame = [icustay_id: int, fluid_intake_amt: double ... 1 more field]\nwarning: there was one deprecation warning; re-run with -deprecation for details\n"}]}},{"text":"/** get the first and last charttime observing  sysBP for the cohort patient **/\nval firstday_vitals = output_filepath+folder+ \"sp_cohort_icd/\"\n//val firstday_vitals =  \"file:/mnt/host/Users/uj149m/Documents/GTECH/CSE6250/Project/outputs/sp_cohort/sp_cohort_icd/\"\nval vitalsy_csvname = \"part*.csv\"\nval sp_cohort_icd = spark.read.format(\"com.databricks.spark.csv\").\n  option(\"header\", \"true\").\n  option(\"mode\", \"DROPMALFORMED\").\n  option(\"delimiter\", \",\").\n  load(firstday_vitals+vitalsy_csvname)\nsp_cohort_icd.createOrReplaceTempView(\"sp_cohort_icd\")\n//sp_cohort_icd.take(5).foreach(println)\n\nval sbp_septic_data =  output_filepath+folder+ \"sbp_septic/\"\nval sbp_septic_csvname = \"part*.csv\"\nval sbp_septic = spark.read.format(\"com.databricks.spark.csv\").\n  option(\"header\", \"true\").\n  option(\"mode\", \"DROPMALFORMED\").\n  option(\"delimiter\", \",\").\n  load(sbp_septic_data+sbp_septic_csvname)\nsbp_septic.createOrReplaceTempView(\"sbp_septic\")\n//sbp_septic.take(5).foreach(println)\n","dateUpdated":"2018-12-10T07:24:01+0000","config":{"colWidth":12,"editorMode":"ace/mode/scala","results":{},"enabled":true,"editorSetting":{"language":"scala"}},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1544422825234_-1696443563","id":"20181115-231849_1888206020","dateCreated":"2018-12-10T06:20:25+0000","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:467","user":"anonymous","dateFinished":"2018-12-10T07:24:03+0000","dateStarted":"2018-12-10T07:24:01+0000","results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"firstday_vitals: String = file:/mnt/host/Users/alla_lvov/git_study/BigDataForHealth/project/data/sp_cohort/sp_cohort_icd/\nvitalsy_csvname: String = part*.csv\nsp_cohort_icd: org.apache.spark.sql.DataFrame = [subject_id: string, hadm_id: string ... 30 more fields]\nsbp_septic_data: String = file:/mnt/host/Users/alla_lvov/git_study/BigDataForHealth/project/data/sp_cohort/sbp_septic/\nsbp_septic_csvname: String = part*.csv\nsbp_septic: org.apache.spark.sql.DataFrame = [icustay_id: string, fluid_intake_amt: string ... 1 more field]\n"}]}},{"text":" /* create the final sp_cohort with septic_shock as per fluid intake using is_septic flag */\n \n  val sp_cohort_icd_ss =  sqlContext.sql(\"\"\"\n  select \n ie.*\n ,ic.is_septic\n-- , v.SS_SBP\n from sp_cohort_icd ie\n left join sbp_septic ic\n     on ie.icustay_id=ic.icustay_id\n\n    \n \"\"\")\n    \n    sp_cohort_icd_ss.registerTempTable(\"sp_cohort_icd_ss\")\n\nwriteOutput(sp_cohort_icd_ss,output_filepath,folder,\"sp_cohort_icd_ss\")\n","dateUpdated":"2018-12-10T06:24:21+0000","config":{"colWidth":12,"editorMode":"ace/mode/scala","results":{},"enabled":true,"editorSetting":{"language":"scala"}},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1544422825236_-1698752057","id":"20181117-213136_1826478763","dateCreated":"2018-12-10T06:20:25+0000","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:468","user":"anonymous","dateFinished":"2018-12-10T07:04:54+0000","dateStarted":"2018-12-10T07:02:45+0000","results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"sp_cohort_icd_ss: org.apache.spark.sql.DataFrame = [subject_id: string, hadm_id: string ... 31 more fields]\nwarning: there was one deprecation warning; re-run with -deprecation for details\n"}]}},{"text":"/** load the data required for calculation the first observations of vitals which will be used as features for sepsis1 prediction */\nval icustay_data = output_filepath+folder+ \"sp_cohort_icd/\"\nval icustay_csvname = \"part*.csv\"\nval icudetails = spark.read.format(\"com.databricks.spark.csv\").\n  option(\"header\", \"true\").\n  option(\"mode\", \"DROPMALFORMED\").\n  option(\"delimiter\", \",\").\n  load(icustay_data+icustay_csvname)\nicudetails.createOrReplaceTempView(\"icudetails\")\n\nval charteventsSchema = StructType(Array(StructField(\"ROW_ID\", IntegerType, true),\n    StructField(\"SUBJECT_ID\", IntegerType, true),\n    StructField(\"HADM_ID\", IntegerType, true),\n    StructField(\"ICUSTAY_ID\", IntegerType, true),\n    StructField(\"ITEMID\", IntegerType, true),\n    StructField(\"CHARTTIME\", TimestampType, true),\n    StructField(\"STORETIME\", TimestampType, true),\n    StructField(\"CGID\", IntegerType, true),\n    StructField(\"VALUE\", StringType, true),\n    StructField(\"VALUENUM\",DoubleType, true),\n    StructField(\"VALUEUOM\", StringType, true),\n    StructField(\"WARNING\", StringType, true),\n    StructField(\"ERROR\", StringType, true),\n    StructField(\"RESULTSTATUS\", StringType, true),\n    StructField(\"STOPPED\", StringType, true)))\n\nregisterSchema(\"CHARTEVENTS.csv\",\"chartevents\",charteventsSchema,filepath,sqlContext)\n\nval icustaysSchema = StructType(Array(StructField(\"ROW_ID\", IntegerType, true),\n    StructField(\"SUBJECT_ID\", IntegerType, true),\n    StructField(\"HADM_ID\", IntegerType, true),\n    StructField(\"ICUSTAY_ID\", IntegerType, true),\n    StructField(\"DBSOURCE\", StringType, true),\n    StructField(\"FIRST_CAREUNIT\", StringType, true),\n    StructField(\"LAST_CAREUNIT\", StringType, true),\n    StructField(\"FIRST_WARDID\", IntegerType, true),\n    StructField(\"LAST_WARDID\", IntegerType, true),\n    StructField(\"INTIME\", TimestampType, true),\n    StructField(\"OUTTIME\", TimestampType, true),\n    StructField(\"LOS\", DoubleType, true)))\n\nregisterSchema(\"ICUSTAYS.csv\",\"icustays\",icustaysSchema,filepath,sqlContext)","dateUpdated":"2018-12-10T06:24:21+0000","config":{"colWidth":12,"editorMode":"ace/mode/scala","results":{},"enabled":true,"editorSetting":{"language":"scala"}},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1544422825237_-1699136806","id":"20181117-214214_845581590","dateCreated":"2018-12-10T06:20:25+0000","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:469","user":"anonymous","dateFinished":"2018-12-10T07:04:56+0000","dateStarted":"2018-12-10T07:02:45+0000","results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"icustay_data: String = file:/mnt/host/Users/alla_lvov/git_study/BigDataForHealth/project/data/sp_cohort/sp_cohort_icd/\nicustay_csvname: String = part*.csv\nicudetails: org.apache.spark.sql.DataFrame = [subject_id: string, hadm_id: string ... 30 more fields]\ncharteventsSchema: org.apache.spark.sql.types.StructType = StructType(StructField(ROW_ID,IntegerType,true), StructField(SUBJECT_ID,IntegerType,true), StructField(HADM_ID,IntegerType,true), StructField(ICUSTAY_ID,IntegerType,true), StructField(ITEMID,IntegerType,true), StructField(CHARTTIME,TimestampType,true), StructField(STORETIME,TimestampType,true), StructField(CGID,IntegerType,true), StructField(VALUE,StringType,true), StructField(VALUENUM,DoubleType,true), StructField(VALUEUOM,StringType,true), StructField(WARNING,StringType,true), StructField(ERROR,StringType,true), StructField(RESULTSTATUS,StringType,true), StructField(STOPPED,StringType,true))\nicustaysSchema: org.apache.spark.sql.types.StructType = StructType(StructField(ROW_ID,IntegerType,true), StructField(SUBJECT_ID,IntegerType,true), StructField(HADM_ID,IntegerType,true), StructField(ICUSTAY_ID,IntegerType,true), StructField(DBSOURCE,StringType,true), StructField(FIRST_CAREUNIT,StringType,true), StructField(LAST_CAREUNIT,StringType,true), StructField(FIRST_WARDID,IntegerType,true), StructField(LAST_WARDID,IntegerType,true), StructField(INTIME,TimestampType,true), StructField(OUTTIME,TimestampType,true), StructField(LOS,DoubleType,true))\n"}]}},{"text":"/* get the vitals in the first 6 hours of ICU admission */\n\nval first6hr = sqlContext.sql(\"\"\"\n with vital_pvt as (\n select ie.subject_id, ie.hadm_id, ie.icustay_id, ce.charttime\n  ,case  when itemid in (211,220045) and valuenum > 0 and valuenum < 300 then 1 -- HeartRate\n    when itemid in (51,442,455,6701,220179,220050) and valuenum > 0 and valuenum < 400 then 2 -- SysBP\n    when itemid in (8368,8440,8441,8555,220180,220051) and valuenum > 0 and valuenum < 300 then 3 -- DiasBP\n    when itemid in (456,52,6702,443,220052,220181,225312) and valuenum > 0 and valuenum < 300 then 4 -- MeanBP\n    when itemid in (615,618,220210,224690) and valuenum > 0 and valuenum < 70 then 5 -- RespRate\n    when itemid in (223761,678) and valuenum > 70 and valuenum < 120  then 6 -- TempF, converted to degC in valuenum call\n    when itemid in (223762,676) and valuenum > 10 and valuenum < 50  then 6 -- TempC\n    when itemid in (646,220277) and valuenum > 0 and valuenum <= 100 then 7 -- SpO2\n    when itemid in (807,811,1529,3745,3744,225664,220621,226537) and valuenum > 0 then 8 -- Glucose\n    else null end as VitalID\n      -- convert F to C\n  , case when itemid in (223761,678) then (valuenum-32)/1.8 else valuenum end as valuenum\n  from icustays ie\n  left join chartevents ce\n  on ie.subject_id = ce.subject_id and ie.hadm_id = ce.hadm_id and ie.icustay_id = ce.icustay_id\n  and ce.charttime between ie.intime and  ( ie.intime + interval '6' hour)\n --  and ce.icustay_id=232134\n  -- exclude rows marked as error\n  WHERE (ce.error = 0 OR ce.error IS NULL) and \n   ce.itemid in\n  (\n  -- HEART RATE\n  211, --\"Heart Rate\"\n  220045, --\"Heart Rate\"\n\n  -- Systolic/diastolic\n\n  51, --\tArterial BP [Systolic]\n  442, --\tManual BP [Systolic]\n  455, --\tNBP [Systolic]\n  6701, --\tArterial BP #2 [Systolic]\n  220179, --\tNon Invasive Blood Pressure systolic\n  220050, --\tArterial Blood Pressure systolic\n\n  8368, --\tArterial BP [Diastolic]\n  8440, --\tManual BP [Diastolic]\n  8441, --\tNBP [Diastolic]\n  8555, --\tArterial BP #2 [Diastolic]\n  220180, --\tNon Invasive Blood Pressure diastolic\n  220051, --\tArterial Blood Pressure diastolic\n\n\n  -- MEAN ARTERIAL PRESSURE\n  456, --\"NBP Mean\"\n  52, --\"Arterial BP Mean\"\n  6702, --\tArterial BP Mean #2\n  443, --\tManual BP Mean(calc)\n  220052, --\"Arterial Blood Pressure mean\"\n  220181, --\"Non Invasive Blood Pressure mean\"\n  225312, --\"ART BP mean\"\n\n  -- RESPIRATORY RATE\n  618,--\tRespiratory Rate\n  615,--\tResp Rate (Total)\n  220210,--\tRespiratory Rate\n  224690, --\tRespiratory Rate (Total)\n\n\n  -- SPO2, peripheral\n  646, 220277,\n\n  -- GLUCOSE, both lab and fingerstick\n  807,--\tFingerstick Glucose\n  811,--\tGlucose (70-105)\n  1529,--\tGlucose\n  3745,--\tBloodGlucose\n  3744,--\tBlood Glucose\n  225664,--\tGlucose finger stick\n  220621,--\tGlucose (serum)\n  226537,--\tGlucose (whole blood)\n\n  -- TEMPERATURE\n  223762, -- \"Temperature Celsius\"\n  676,\t-- \"Temperature C\"\n  223761, -- \"Temperature Fahrenheit\"\n  678 --\t\"Temperature F\"\n\n  )\n  order by  ie.icustay_id, ce.charttime\n )\n ,  vital_pvt2 as (\n \n  SELECT subject_id, hadm_id, icustay_id\n   , VitalID, valuenum\n--  ,case when VitalID = 1 then valuenum else null end as HeartRate\n--   ,case when VitalID =2 then valuenum else null end as SysBP\n--  from \n--  (select *, row_number() over (PARTITION BY icustay_id, VitalID order by  charttime) as rn from heartrate_pvt) tmp where rn =1\n , ROW_NUMBER() over \n  (\n     PARTITION BY icustay_id, VitalID\n     ORDER BY charttime\n  )\n      as index_row\n      from  vital_pvt\n)\n, vital_pvt3 as (\nselect subject_id, hadm_id, icustay_id\n, case when VitalID = 1 then valuenum  end as HeartRate \n, case when VitalID = 2 then valuenum end as SysBP\n, case when VitalID = 3 then valuenum end as DiasBP\n, case when VitalID = 4 then valuenum  end as MeanBP\n, case when VitalID = 5 then valuenum  end as RespRate\n, case when VitalID = 6 then valuenum  end as TempC\n, case when VitalID = 7 then valuenum end as SpO2\n, case when VitalID = 8 then valuenum end as Glucose\nfrom vital_pvt2 where  index_row=1\n-- group by  subject_id, hadm_id, icustay_id, VitalID\norder by subject_id, hadm_id, icustay_id\n)\nselect  subject_id, hadm_id, icustay_id\n,max(HeartRate) as HeartRate\n,max(SysBP) as SysBP\n,max(DiasBP) as DiasBP\n,max(MeanBP) as MeanBP\n,max(RespRate) as RespRate\n,max(TempC) as TempC\n,max(SpO2) as SpO2\n,max(Glucose) as Glucose\n\nfrom vital_pvt3\ngroup by  subject_id, hadm_id,icustay_id\norder by  subject_id, hadm_id,icustay_id\n\n   \n   \"\"\")\n   \n   first6hr.registerTempTable(\"first6hrVitals\")\n\nwriteOutput(first6hr,output_filepath,folder,\"first6hrVitals\")","dateUpdated":"2018-12-10T06:24:21+0000","config":{"colWidth":12,"editorMode":"ace/mode/scala","results":{},"enabled":true,"editorSetting":{"language":"scala"}},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1544422825239_-1698367308","id":"20181128-192918_110426089","dateCreated":"2018-12-10T06:20:25+0000","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:470","user":"anonymous","dateFinished":"2018-12-10T07:07:21+0000","dateStarted":"2018-12-10T07:04:55+0000","results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"first6hr: org.apache.spark.sql.DataFrame = [subject_id: int, hadm_id: int ... 9 more fields]\nwarning: there was one deprecation warning; re-run with -deprecation for details\n"}]}},{"text":" /** create the features for spesis1 **/\n val sepsis1_features = sqlContext.sql(\"\"\"\n    \n    select \n     ie.*\n    ,vi.HeartRate,vi.SysBP,vi.DiasBP,vi.MeanBP,vi.RespRate,vi.TempC,vi.SpO2,vi.Glucose\n\nfrom icudetails ie\n left join first6hrVitals vi on\n    ie.icustay_id = vi.icustay_id\n\n order by  ie.icustay_id\n \n \"\"\")\n \n sepsis1_features.registerTempTable(\"sepsis1_features\")\nwriteOutput(sepsis1_features,output_filepath,folder,\"sepsis1_features\")","dateUpdated":"2018-12-10T06:24:21+0000","config":{"colWidth":12,"editorMode":"ace/mode/scala","results":{},"enabled":true,"editorSetting":{"language":"scala"}},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1544422825240_-1700291052","id":"20181128-193032_1838205076","dateCreated":"2018-12-10T06:20:25+0000","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:471","user":"anonymous","dateFinished":"2018-12-10T07:09:58+0000","dateStarted":"2018-12-10T07:04:56+0000","results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"sepsis1_features: org.apache.spark.sql.DataFrame = [subject_id: string, hadm_id: string ... 38 more fields]\nwarning: there was one deprecation warning; re-run with -deprecation for details\n"}]}},{"dateUpdated":"2018-12-10T06:20:25+0000","config":{"colWidth":12,"editorMode":"ace/mode/scala","results":{},"enabled":true,"editorSetting":{"language":"scala"}},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1544422825243_-1699906303","id":"20181128-193922_1475867572","dateCreated":"2018-12-10T06:20:25+0000","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:472"}],"name":"sp_cohort","id":"2DWJMAAJN","angularObjects":{"2DY6G4N6P:shared_process":[],"2DYR2RMZA:shared_process":[],"2DYYJG7NN:shared_process":[],"2DVX43H2V:shared_process":[],"2DWED52WG:shared_process":[],"2DVN654C2:shared_process":[],"2DXH7QCKA:shared_process":[]},"config":{"looknfeel":"default","personalizedMode":"false"},"info":{}}